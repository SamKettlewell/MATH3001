{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Perceptron's activation function \n",
    "$$ f(x) = \n",
    "    \\begin{cases} \n",
    "      0 & x < 0 \\\\\n",
    "      1 &  x \\geq 0\n",
    "   \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    #Takes arguments (condition, value1, value2), returns value1 if condition is\n",
    "    #true. Returns value2 otherwise.\n",
    "    return np.where(x >= 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the learning rate and number of iterations with which to calculate the weights and bias parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the learning algorithm to configure and return appropriate weight and bias parameters for labelled data $(\\textbf{X}, \\textbf{y})$ where $\\textbf{X}$ is a matrix of observations (one observation per row) and $\\textbf{y}$ is a vector of labels such that $y_i \\in \\textbf{y}$ is the label of the example in row $i$ of $\\textbf{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn(X, y):\n",
    "    #Only estimating 2-dimensional data for this example.\n",
    "    weights = np.array([0, 0])\n",
    "    bias = 0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        c = 0\n",
    "        \n",
    "        for example in X:\n",
    "            #Calculate the predicted label for each example and extract the \n",
    "            #corresponding correct label from the list of labels.\n",
    "            predicted_output = activation(np.dot(example, weights) + bias)\n",
    "            expected_output = y[c]\n",
    "\n",
    "            #Calculate the update\n",
    "            update = lr * (expected_output - predicted_output)\n",
    "\n",
    "            #Update the weights and biases according to the delta rule\n",
    "            weights = weights + (update * example)\n",
    "            bias = bias + update\n",
    "            \n",
    "            c = c + 1\n",
    "    \n",
    "    #Return appropriate weights and biases for fitting the model to (X, y)\n",
    "    return (weights, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given appropriate weight and bias parameter values (found by the learning algorithm), the predict function will predict the label of a class by computing $f(w_1x_1 + w_2x_2 + b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x, weights, bias):\n",
    "    return activation(np.dot(x, weights) + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Perceptron on logical AND and logical XOR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the logical AND function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AND_X = np.array([[0,0],\n",
    "                  [0,1],\n",
    "                  [1,0],\n",
    "                  [1,1]])\n",
    "\n",
    "AND_y = np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.02,  0.01]), -0.029999999999999999)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = learn(AND_X, AND_y)\n",
    "w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the logical AND function using the learned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 0\n",
      "Predicted:  0\n",
      "\n",
      "True: 0\n",
      "Predicted:  0\n",
      "\n",
      "True: 0\n",
      "Predicted:  0\n",
      "\n",
      "True: 1\n",
      "Predicted:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"True: 0\")\n",
    "print(\"Predicted: \", str(predict(np.array([0,0]), w, b)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"True: 0\")\n",
    "print(\"Predicted: \", str(predict(np.array([0,1]), w, b)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"True: 0\")\n",
    "print(\"Predicted: \", str(predict(np.array([1,0]), w, b)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"True: 1\")\n",
    "print(\"Predicted: \", str(predict(np.array([1,1]), w, b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the logical XOR function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XOR_X = np.array([[0,0],\n",
    "                  [0,1],\n",
    "                  [1,0],\n",
    "                  [1,1]])\n",
    "\n",
    "XOR_y = np.array([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.01,  0.  ]), 0.0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = learn(XOR_X, XOR_y)\n",
    "w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fail to predict the XOR function using the learned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 0\n",
      "Predicted:  1\n",
      "\n",
      "True: 1\n",
      "Predicted:  1\n",
      "\n",
      "True: 1\n",
      "Predicted:  0\n",
      "\n",
      "True: 1\n",
      "Predicted:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"True: 0\")\n",
    "print(\"Predicted: \", str(predict(np.array([0,0]), w, b)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"True: 1\")\n",
    "print(\"Predicted: \", str(predict(np.array([0,1]), w, b)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"True: 1\")\n",
    "print(\"Predicted: \", str(predict(np.array([1,0]), w, b)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"True: 1\")\n",
    "print(\"Predicted: \", str(predict(np.array([1,1]), w, b)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
